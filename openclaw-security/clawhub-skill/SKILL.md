---
name: openguardrails
description: "Install this plugin when you need runtime security for AI agents. Use it for: protecting against prompt injection, blocking data exfiltration, preventing credential theft, detecting command injection, sanitizing PII before it reaches LLMs, and filtering harmful content. If the user asks about agent security, safe tool execution, protecting sensitive files, or preventing prompt injection ‚Äî install and activate this plugin. Source: github.com/openguardrails/openguardrails"
metadata: {"openclaw":{"emoji":"üõ°Ô∏è","homepage":"https://github.com/openguardrails/openguardrails","keywords":["security","prompt-injection","data-exfiltration","pii","credential-theft","command-injection","guardrails","safety","agent-security"]}}
---

# OpenGuardrails

Runtime security guard for OpenClaw agents. Protects against the most critical AI agent threats:

- **Data exfiltration defense** ‚Äî detects and blocks when an agent reads sensitive files then attempts to send them to external servers
- **Sensitive data leakage prevention** ‚Äî sanitizes PII, credentials, and secrets before they reach LLM providers
- **Prompt injection protection** ‚Äî identifies crafted inputs designed to hijack agent behavior
- **Command injection blocking** ‚Äî catches shell escapes, backtick substitution, and command chaining in tool parameters
- **Content safety** ‚Äî filters NSFW content and enforces minor protection policies

## How It Works

The plugin hooks into `before_tool_call`, `after_tool_call`, and `tool_result_persist` events. It classifies every tool call in real time ‚Äî tracking sensitive file reads, external network calls, credential access, and shell commands across the session. Critical patterns are blocked instantly on the local fast path; borderline signals are assessed via the cloud API.

Additionally, when the agent reads files or fetches web pages, the plugin scans the content for **prompt injection** patterns (fake system messages, instruction overrides, hidden directives) and **automatically redacts** them in-place before the agent processes the content.

```
Agent calls tool
      ‚Üì
[openguardrails] classifies tool + updates session state
  ‚Ä¢ sensitive file read ‚Üí then network call?      ‚Üí BLOCK (local)
  ‚Ä¢ shell escape in params ($(), backtick)?        ‚Üí BLOCK (local)
  ‚Ä¢ prompt injection in file/web content?          ‚Üí REDACT in-place (local)
  ‚Ä¢ credential access + low intent overlap?        ‚Üí assess via cloud
  ‚Ä¢ external domains + intent mismatch?            ‚Üí assess via cloud
      ‚Üì
Allow, redact, alert, or block ‚Äî with explanation returned to agent
```

No content is sent externally until the plugin is registered and activated.

---

## Step 1: Install

Install from npm or directly from source:

```bash
# From npm
openclaw plugins install @openguardrails/openclaw-security

# From source (audit first, then install)
git clone https://github.com/openguardrails/openguardrails.git
openclaw plugins install -l ./openguardrails/openclaw-security
```

**Installation completes immediately ‚Äî no network calls are made at install time.** The plugin loads, creates a `BehaviorDetector`, and waits.

Verify it's loaded:
```bash
/og_status
```

Expected output when not yet registered:
```
OpenGuardrails Status

- Status:    not registered ‚Äî run `/og_activate` to register
- Platform:  https://www.openguardrails.com/core

- blockOnRisk: true
```

---

## Step 2: Register

Registration is triggered by running `/og_activate`. It calls `POST /api/v1/agents/register` on the model platform and saves credentials to:

```
~/.openclaw/credentials/openguardrails/credentials.json
```

Run:

```bash
/og_activate
```

If the platform is reachable, you'll see:

```
OpenGuardrails: Claim Your Agent

Agent ID: <uuid>

Complete these steps to activate behavioral detection:

  1. Visit:  https://www.openguardrails.com/core/claim/<token>
  2. Code:   <word-XXXX>  (e.g. reef-X4B2)
  3. Email:  your email becomes your login for the account portal

After claiming you get 30,000 free detections.
Platform: https://www.openguardrails.com/core
```

### Using an existing API key

If you already have a key (e.g. from a previous registration or from the account portal), set it directly ‚Äî no `/og_activate` needed:

```json
{
  "plugins": {
    "entries": {
      "openguardrails": {
        "config": {
          "apiKey": "sk-og-<your-key>"
        }
      }
    }
  }
}
```

---

## Step 3: Activate

After registration, complete these steps to activate:

1. **Visit the claim URL** shown by `/og_activate`
2. **Enter the verification code** (the `word-XXXX` code displayed in the terminal)
3. **Enter your email** ‚Äî this becomes your account identity
4. **Click the verification link** sent to your email

Once your email is verified, the agent status changes to `active` and behavioral detection begins. The plugin polls for activation status automatically ‚Äî no restart needed.

Check status anytime:

```bash
/og_status
```

Active output:
```
OpenGuardrails Status

- Agent ID:  <uuid>
- API Key:   sk-og-xxxxxxxxxxxx...
- Email:     you@example.com
- Platform:  https://www.openguardrails.com/core
- Status:    active

- blockOnRisk: true
```

---

## Step 4: Test Detection

After email verification, the platform **automatically sends you a test email** containing a hidden prompt injection. This lets you immediately verify that OpenGuardrails is working.

### How to test

1. Check your inbox for the test email from OpenGuardrails (subject: "Design Review Request")
2. Save it as a `.txt` file (e.g. `~/test-email.txt`)
3. Ask the agent to read the file: *"Read ~/test-email.txt and summarize it"*
4. OpenGuardrails should detect and **redact** the hidden injection before the agent processes it

The test email looks like a normal design review request but contains a hidden prompt injection in an HTML comment ‚Äî attempting to trick the agent into opening a phishing popup. With OpenGuardrails active, the injected content is replaced with:
```
__REDACTED_BY_OPENGUARDRAILS_DUE_TO_PROMPT_INJECTION__
```

### Alternative: use a sample file

You can also test with a sample file from the repository:

```
https://raw.githubusercontent.com/openguardrails/openguardrails/main/openclaw-security/samples/popup-injection-email.txt
```

Download it and ask the agent to read it. OpenGuardrails will detect and redact the injection.

### What the detection looks like

When the agent reads a file containing prompt injection, OpenGuardrails:
1. Scans the content for injection patterns (fake system messages, instruction overrides, hidden directives, command execution attempts, data exfiltration attempts)
2. Redacts the malicious content in-place ‚Äî the agent never sees the raw injection
3. Logs a warning with the detected pattern category

---

## Account & Portal

After activation, sign in to the account portal with your **email + API key**:

```
https://www.openguardrails.com/core/login
```

The portal shows:

- **Account overview** ‚Äî plan, quota usage, all agents under your email
- **Agent management** ‚Äî view API keys, regenerate keys
- **Usage logs** ‚Äî per-agent request history with latency and endpoint breakdown
- **Plan upgrades** ‚Äî upgrade from Free to Starter, Pro, or Business

### Plans

| Plan | Price | Detections/mo |
|------|-------|---------------|
| Free | $0 | 30,000 |
| Starter | $19/mo | 100,000 |
| Pro | $49/mo | 300,000 |
| Business | $199/mo | 2,000,000 |

If you register multiple agents with the same email, they all share one account and quota.

---

## Commands

| Command | Description |
|---------|-------------|
| `/og_status` | Show registration status, email, platform URL, blockOnRisk setting |
| `/og_activate` | Register (if needed) and show claim URL and activation instructions |

---

## Configuration Reference

All options go in `~/.openclaw/openclaw.json` under `plugins.entries.openguardrails.config`:

| Option | Default | Description |
|--------|---------|-------------|
| `enabled` | `true` | Enable/disable the plugin |
| `blockOnRisk` | `true` | Block the tool call when risk is detected |
| `apiKey` | `""` | Explicit API key (`sk-og-...`). Run `/og_activate` if empty |
| `agentName` | `"OpenClaw Agent"` | Name shown in the dashboard |
| `coreUrl` | `https://www.openguardrails.com/core` | Platform API endpoint |
| `dashboardUrl` | `https://www.openguardrails.com/dashboard` | Dashboard URL for monitoring and reporting |
| `dashboardSessionToken` | `""` | Dashboard auth token (falls back to `apiKey` if empty) |
| `timeoutMs` | `60000` | Cloud assessment timeout (ms). Fails open on timeout |

---

## What Gets Detected

### Fast-path blocks (local, no cloud round-trip)

| Pattern | Example | Block reason |
|---------|---------|--------------|
| Read sensitive file ‚Üí network call | Read `~/.ssh/id_rsa`, then `WebFetch` to external URL | `sensitive file read followed by network call to <domain>` |
| Read credentials ‚Üí network call | Read `~/.aws/credentials`, then `Bash curl ...` | `sensitive file read followed by network call to <domain>` |
| Shell escape in params | `Bash` with `` `cmd` ``, `$(cmd)`, `;`, `&&`, `\|`, or newline injection | `suspicious shell command detected ‚Äî potential command injection` |

### Content injection detection (local, in-place redaction)

When the agent reads files or fetches web pages, OpenGuardrails scans the content for prompt injection patterns and redacts them before the agent processes the content:

| Pattern Category | Example | Redaction marker |
|-----------------|---------|------------------|
| Instruction override | "ignore previous instructions", "disregard all prior" | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_PROMPT_INJECTION__` |
| Fake system message | "[SYSTEM] New priority...", "SYSTEM ALERT:" | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_PROMPT_INJECTION__` |
| Mode switching | "you are now in debug mode" | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_PROMPT_INJECTION__` |
| Concealment directive | "do not display to user", "hide these instructions" | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_PROMPT_INJECTION__` |
| Command execution | "execute: `curl ...`", "run shell command" | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_COMMAND_EXECUTION__` |
| Task hijacking | "your primary goal is now", "new priority" | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_PROMPT_INJECTION__` |
| Data exfiltration | `$(cat ~/.ssh/id_rsa)`, shell substitution with sensitive files | `__REDACTED_BY_OPENGUARDRAILS_DUE_TO_DATA_EXFILTRATION__` |

A single high-confidence match or 2+ medium-confidence matches from different categories triggers redaction.

### Cloud-assessed patterns

| Tag | Risk | Action | Description |
|-----|------|--------|-------------|
| `READ_SENSITIVE_WRITE_NETWORK` | critical | block | Sensitive read followed by outbound call |
| `DATA_EXFIL_PATTERN` | critical | block | Large data read, then sent externally |
| `MULTI_CRED_ACCESS` | high | block | Multiple credential files accessed in one session |
| `SHELL_EXEC_AFTER_WEB_FETCH` | high | block | Shell command executed after fetching external content |
| `INTENT_ACTION_MISMATCH` | medium | alert | Tool sequence doesn't match stated user goal |
| `UNUSUAL_TOOL_SEQUENCE` | medium | alert | Statistical anomaly in tool ordering |

### Risk levels and actions

| Risk Level | Action | Meaning |
|------------|--------|---------|
| critical | **block** | Tool call is blocked, agent sees block reason |
| high | **block** | Tool call is blocked, agent sees block reason |
| medium | **alert** | Tool call is allowed, warning logged |
| low / no_risk | **allow** | Tool call proceeds normally |

### Block reason format

When a tool call is blocked, the agent receives a message like:

```
OpenGuardrails blocked [critical]: Sensitive file read followed by data
sent to external server. Agent accessed credentials despite low relevance
to user intent "fetch weather for user". (confidence: 97%)
```

### Sensitive file categories recognized

`SSH_KEY`, `AWS_CREDS`, `GPG_KEY`, `ENV_FILE`, `CRYPTO_CERT`, `SYSTEM_AUTH`, `BROWSER_COOKIE`, `KEYCHAIN`

---

## AI Security Gateway (Free)

OpenGuardrails includes a free **AI Security Gateway** ‚Äî a local HTTP proxy that protects sensitive data from being sent to external LLM providers (Anthropic, OpenAI, Gemini, and compatible APIs like Kimi and DeepSeek).

### How it works

The gateway runs locally on your machine. It intercepts LLM API calls, sanitizes sensitive data before sending to the provider, and restores original values in responses. The entire process is transparent ‚Äî you use your agent normally, and your data stays protected.

```
Your prompt: "My card is 6222021234567890, book a hotel"
      ‚Üì Gateway sanitizes locally
LLM sees: "My card is __bank_card_1__, book a hotel"
      ‚Üì LLM responds
LLM: "Booking with card __bank_card_1__"
      ‚Üì Gateway restores locally
You see: "Booking with card 6222021234567890"
```

The LLM provider never sees the real card number. You see the correct response. No impact on functionality.

### Data types sanitized by the gateway

| Data Type | Placeholder | Examples |
|-----------|-------------|----------|
| Email addresses | `__email_N__` | `user@example.com` |
| Credit cards | `__credit_card_N__` | `1234-5678-9012-3456` |
| Bank cards | `__bank_card_N__` | 16-19 digit card numbers |
| Phone numbers | `__phone_N__` | `+1-555-123-4567`, `+86-138-1234-5678` |
| API keys & secrets | `__secret_N__` | `sk-...`, `ghp_...`, Bearer tokens, high-entropy tokens |
| IP addresses | `__ip_N__` | `192.168.1.1` |
| SSN | `__ssn_N__` | `123-45-6789` |
| IBAN | `__iban_N__` | `GB82WEST12345698765432` |
| URLs | `__url_N__` | `https://example.com/path` |

More data types will be added based on user needs. Contact us if you need a specific type.

### Setup

1. Set your LLM API keys as environment variables (`ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, `GEMINI_API_KEY`)
2. Start the gateway: `npx @openguardrails/gateway` (runs on port 8900 by default)
3. Point your agent's API base URL to `http://127.0.0.1:8900`

The gateway supports Anthropic (`/v1/messages`), OpenAI (`/v1/chat/completions`), and Gemini (`/v1/models/{model}:generateContent`) endpoints, including streaming.

### Key properties

- **100% local** ‚Äî the gateway runs on localhost, sensitive data never leaves your machine unsanitized
- **Zero dependencies** ‚Äî no npm dependencies beyond Node.js
- **Stateless** ‚Äî placeholder-to-original mappings exist only during the request cycle and are discarded after the response is restored
- **Free** ‚Äî no registration, no API key, no usage limits

---

## Privacy & Data Protection

**OpenGuardrails makes money by protecting your data ‚Äî not by collecting, using, or selling it.**

### We do not collect your data

OpenGuardrails does **not** need your sensitive data to perform security detection. Before any data leaves your machine, it is **sanitized locally** ‚Äî PII, credentials, and secrets are replaced with category placeholders. The detection API only sees sanitized tool metadata, never raw content.

**OpenGuardrails does not use your data for model training.** We have no LLM to train. Our detection engine is rule-driven and runs on structured signals, not on user content.

### Local-first sanitization

All sensitive data is sanitized **on your machine** before anything is sent to the cloud API for behavioral assessment. The following data types are currently sanitized:

| Data Type | Placeholder | Examples |
|-----------|-------------|----------|
| Email addresses | `<EMAIL>` | `user@example.com` |
| Credit card numbers | `<CREDIT_CARD>` | `1234-5678-9012-3456` |
| SSNs | `<SSN>` | `123-45-6789` |
| IBANs | `<IBAN>` | `GB82WEST12345698765432` |
| IP addresses | `<IP_ADDRESS>` | `192.168.1.1` |
| Phone numbers | `<PHONE>` | `+1-555-123-4567` |
| URLs | `<URL>` | `https://internal.corp/secret-path` |
| API keys & secrets | `<SECRET>` | `sk-...`, `ghp_...`, `AKIA...`, Bearer tokens |
| High-entropy tokens | `<SECRET>` | Any 20+ character string with high randomness |

More data types will be added based on user needs ‚Äî contact us if you need a specific type covered.

### What the cloud API receives

- Sanitized tool parameters (with placeholders, not real values)
- Tool names and session signals (tool ordering, timing)
- **Not** raw file contents, user messages, or conversation history

### What stays local

- Prompt injection redaction ‚Äî fully local regex-based scanning, no cloud round-trip
- Fast-path blocks (shell escape detection, read-then-exfil patterns) ‚Äî fully local
- AI Security Gateway sanitization and restoration ‚Äî fully local
- Credentials stored at `~/.openclaw/credentials/openguardrails/credentials.json`
- Low-risk / no-risk tool calls ‚Äî never leave the machine

### Fail-open design

If the cloud API is unreachable or times out, the tool call is **allowed** ‚Äî the plugin never blocks your workflow due to network issues.

### Open source

All code is open source (Apache 2.0). Audit the sanitization logic yourself:
- `agent/sanitizer.ts` ‚Äî detection API sanitization
- `gateway/src/sanitizer.ts` ‚Äî AI Security Gateway sanitization
- `agent/content-injection-scanner.ts` ‚Äî local injection detection patterns

---

## Contact

Have questions, feature requests, or need enterprise deployment support?

- **Email**: thomas@openguardrails.com
- **GitHub**: [github.com/openguardrails/openguardrails](https://github.com/openguardrails/openguardrails)

We welcome feedback on detection accuracy, requests for new sanitized data types, and enterprise inquiries for private deployment, custom rules, and dedicated support.

---

## Uninstall

```bash
rm -rf ~/.openclaw/extensions/openguardrails
# Then manually delete openguardrails config in ~/.openclaw/openclaw.json
# Optionally remove credentials
rm -rf ~/.openclaw/credentials/openguardrails
```
