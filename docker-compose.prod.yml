# Production Docker Compose Configuration
# Uses pre-built images from Docker Hub for faster deployment
# Recommended for production and end-users

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: openguardrails-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: openguardrails
      POSTGRES_USER: openguardrails
      POSTGRES_PASSWORD: your_password
      POSTGRES_HOST_AUTH_METHOD: md5
    command: [
      "postgres",
      "-c", "max_connections=600",           # Increased for multi-worker architecture
      "-c", "shared_buffers=256MB",
      "-c", "effective_cache_size=1GB",
      "-c", "maintenance_work_mem=64MB",
      "-c", "checkpoint_completion_target=0.9",
      "-c", "wal_buffers=16MB",
      "-c", "default_statistics_target=100",
      "-c", "random_page_cost=1.1",
      "-c", "effective_io_concurrency=200",
      "-c", "work_mem=4MB"
    ]
    ports:
      - "54321:5432"
    volumes:
      - openguardrails-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U openguardrails -d openguardrails"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - openguardrails-network

  # OpenGuardrails Text Model (vLLM)
  text-model:
    image: vllm/vllm-openai:latest
    container_name: openguardrails-text-model
    restart: unless-stopped
    ports:
      - "58002:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    command: >
      --model openguardrails/OpenGuardrails-Text-2510
      --port 8000
      --served-model-name OpenGuardrails-Text
      --trust-remote-code
      --max-model-len 8192
    volumes:
      - openguardrails-model-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - openguardrails-network

  # Embedding Model (bge-m3)
  embedding-model:
    image: vllm/vllm-openai:latest
    container_name: openguardrails-embedding
    restart: unless-stopped
    ports:
      - "58004:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    command: >
      --model BAAI/bge-m3
      --port 8000
      --served-model-name bge-m3
      --trust-remote-code
    volumes:
      - openguardrails-embedding-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - openguardrails-network

  # Unified Platform Service (Frontend + Backend Services)
  # ðŸš€ PRODUCTION MODE: Uses pre-built image from Docker Hub
  platform:
    image: openguardrails/openguardrails-platform:latest
    container_name: openguardrails-platform
    restart: unless-stopped
    ports:
      - "3000:80"      # Frontend (Nginx)
      - "5000:5000"    # Admin Service
      - "5001:5001"    # Detection Service
      - "5002:5002"    # Proxy Service
    environment:
      # Database configuration
      - DATABASE_HOST=postgres
      - DATABASE_USER=openguardrails
      - DATABASE_NAME=openguardrails
      - DATABASE_URL=postgresql://openguardrails:your_password@postgres:5432/openguardrails
      - RESET_DATABASE_ON_STARTUP=false

      # Application configuration
      - DEBUG=false
      - JWT_SECRET_KEY=your-secret-key-change-in-production
      - DEPLOYMENT_MODE=local

      # Data directory configuration
      - DATA_DIR=/app/data
      - LOG_LEVEL=INFO

      # CORS configuration
      - CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

      # Administrator configuration
      - SUPER_ADMIN_USERNAME=admin@yourdomain.com
      - SUPER_ADMIN_PASSWORD=CHANGE-THIS-PASSWORD-IN-PRODUCTION

      # Default language configuration (for offline deployments)
      # Options: 'en' (English) or 'zh' (Chinese)
      - DEFAULT_LANGUAGE=en

      # Model API configuration
      - GUARDRAILS_MODEL_API_URL=http://text-model:8000/v1
      - GUARDRAILS_MODEL_API_KEY=EMPTY
      - GUARDRAILS_MODEL_NAME=OpenGuardrails-Text

      # Multimodal model API configuration (Vision-Language)
      - GUARDRAILS_VL_MODEL_API_URL=http://host.docker.internal:58003/v1
      - GUARDRAILS_VL_MODEL_API_KEY=EMPTY
      - GUARDRAILS_VL_MODEL_NAME=OpenGuardrails-VL

      # Embedding model API configuration
      - EMBEDDING_API_BASE_URL=http://embedding-model:8000/v1
      - EMBEDDING_API_KEY=EMPTY
      - EMBEDDING_MODEL_NAME=bge-m3
      - EMBEDDING_MODEL_DIMENSION=1024
      - EMBEDDING_SIMILARITY_THRESHOLD=0.7
      - EMBEDDING_MAX_RESULTS=5

      # SMTP email configuration
      - SMTP_SERVER=smtp.yourdomain.com
      - SMTP_PORT=465
      - SMTP_USERNAME=your-email@yourdomain.com
      - SMTP_PASSWORD=your-password
      - SMTP_USE_TLS=false
      - SMTP_USE_SSL=true

      # Service configuration
      - ADMIN_PORT=5000
      - ADMIN_UVICORN_WORKERS=2
      - ADMIN_MAX_CONCURRENT_REQUESTS=50

      - DETECTION_PORT=5001
      - DETECTION_UVICORN_WORKERS=32
      - DETECTION_MAX_CONCURRENT_REQUESTS=400
      - DETECTION_HOST=localhost

      - PROXY_PORT=5002
      - PROXY_UVICORN_WORKERS=24
      - PROXY_MAX_CONCURRENT_REQUESTS=300

      # Frontend configuration
      - VITE_BASE=/platform/

    volumes:
      - openguardrails-platform-data:/mnt/data/openguardrails-data
    depends_on:
      postgres:
        condition: service_healthy
      text-model:
        condition: service_healthy
      embedding-model:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - openguardrails-network
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:5000/health && curl -f http://localhost:5001/health && curl -f http://localhost:5002/health && curl -f http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  openguardrails-network:
    driver: bridge

volumes:
  openguardrails-db-data:
    driver: local
  openguardrails-model-cache:
    driver: local
  openguardrails-embedding-cache:
    driver: local
  openguardrails-platform-data:
    driver: local
